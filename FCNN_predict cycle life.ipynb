{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\joan3567\\anaconda2\\envs\\cs230\\lib\\site-packages (1.0.1)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorchtools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5bd674e76702>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip install torch '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpytorchtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEarlystopping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pytorchtools'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import struct\n",
    "import sys\n",
    "from array import array\n",
    "from os import path\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn import preprocessing\n",
    "import png\n",
    "import numpy as np\n",
    "!pip install torch \n",
    "import torch\n",
    "from pytorchtools import Earlystopping\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('c:/Data/X_train_first-100-cyc_60.csv', header= None).T\n",
    "Y_train = pd.read_csv('c:/Data/Y_train_first-100-cyc_60.csv', header= None).T\n",
    "Y_train_class = (Y_train >= 550)\n",
    "\n",
    "save_path = 'c:/Data/output/FCC/Y_train_newdatasplit.csv'\n",
    "np.savetxt(save_path, Y_train, delimiter=',')\n",
    "\n",
    "\n",
    "#print ('Y_train_class.shape',Y_train_class.shape)\n",
    "#print ('Y_train_class',Y_train_class)\n",
    "#print ('X_train.shape', X_train.shape)\n",
    "\n",
    "X_train = torch.tensor(X_train.values).float()\n",
    "Y_train = torch.tensor(Y_train.values).float()\n",
    "Y_train_class = Y_train_class *1\n",
    "Y_train_class = torch.tensor(Y_train_class.values).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = pd.read_csv('c:/Data/X_dev_first-100-cyc_20.csv', header= None).T\n",
    "Y_dev = pd.read_csv('c:/Data/Y_dev_first-100-cyc_20.csv', header= None).T\n",
    "X_dev = torch.tensor(X_dev.values).float()\n",
    "Y_dev = torch.tensor(Y_dev.values).float()\n",
    "\n",
    "save_path = 'c:/Data/output/FCC/Y_dev_newdatasplit3.csv'\n",
    "np.savetxt(save_path, Y_dev, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('c:/Data/X_test_first-100-cyc_20.csv', header= None).T\n",
    "Y_test = pd.read_csv('c:/Data/Y_test_first-100-cyc_20.csv', header= None).T\n",
    "X_test = torch.tensor(X_test.values).float()\n",
    "Y_test = torch.tensor(Y_test.values).float()\n",
    "\n",
    "\n",
    "save_path = 'c:/Data/output/FCC/Y_test_newdatasplit3.csv'\n",
    "np.savetxt(save_path, Y_test, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm = preprocessing.scale(X_train, axis=0, with_mean=True, with_std=True, copy=True)\n",
    "X_train_norm = torch.tensor(X_train_norm).float()\n",
    "#np.savetxt('./Data/X_train_norm.csv', X_train_norm, delimiter=',')\n",
    "\n",
    "X_dev_norm = preprocessing.scale(X_dev, axis=0, with_mean=True, with_std=True, copy=True)\n",
    "X_dev_norm = torch.tensor(X_dev_norm).float()\n",
    "#np.savetxt('c:/Data/X_train_norm.csv', X_train_norm, delimiter=',')\n",
    "\n",
    "X_test_norm = preprocessing.scale(X_test, axis=0, with_mean=True, with_std=True, copy=True)\n",
    "X_test_norm = torch.tensor(X_test_norm).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Define the model\n",
    "\n",
    "#2-layer neural network (LINEAR->RELU->LINEAR->SOFTMAX)\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model = nn.Sequential(\n",
    "    #Flatten(),\n",
    "    nn.Linear(800, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 1),\n",
    "    nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Define loss function and optimizer\n",
    "\n",
    "#We will use the cross entropy loss and Adam optimizer\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the cost function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer, learning rate \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_per_iteration = []\n",
    "for i in range(10000):\n",
    "    # zero the parameter \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # forward propogatiom\n",
    "    outputs = model(X_train)\n",
    "    #print('outputs', outputs)\n",
    "    #print('Y_train',Y_train)\n",
    "    #print ('outputs', outputs)\n",
    "    # calculate the loss\n",
    "    loss = torch.sqrt(criterion(outputs, Y_train))\n",
    "    print ('loss',loss)\n",
    "\n",
    "    # backpropogation + update parameters\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    cost = loss.item()\n",
    "    cost_per_iteration.append(cost)\n",
    "    if i % 100 == 0:  # print every 1000 iterations\n",
    "        print('Epoch:' + str(i) + \", Iteration: \" + str(i)\n",
    "              + \", training cost = \" + str(cost))\n",
    "        #print('outputs: ', outputs)\n",
    "        # for name, param in model.named_parameters():\n",
    "        #     if param.requires_grad:\n",
    "        #         print (name, param.data)\n",
    "        \n",
    "save_path = 'c:/Data/output/FCC/FCC_actualcyclelife_learning0.01.csv'\n",
    "np.savetxt(save_path, cost_per_iteration, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_percentage_error(X, Y):\n",
    "    outputs = model(X)\n",
    "    Y_pred = outputs \n",
    "    \n",
    "    Y_pred = Y_pred.float()\n",
    "    divider = torch.abs(Y_pred - Y) \n",
    "    divider2 = divider / Y * 100\n",
    "    outputsize = Y.shape[0]\n",
    "    sum = torch.sum(divider2)\n",
    "    error= sum / outputsize\n",
    "    Y_pred = Y_pred.detach().numpy()\n",
    "    print('Y_pred', Y_pred)\n",
    "\n",
    "    #save_path = 'c:/Data/output/Y_pred1.csv'\n",
    "    #np.savetxt(save_path, Y_pred, delimiter=',')\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_percentage_error = calculate_percentage_error(X_train, Y_train)\n",
    "\n",
    "outputs = model(X_train)\n",
    "outputs = outputs.detach().numpy()\n",
    "save_path = 'c:/Data/output/Y_pred_train_learningrate=0.01_newdataset2.csv'\n",
    "np.savetxt(save_path, outputs, delimiter=',')\n",
    "dev_percentage_error = calculate_percentage_error(X_dev, Y_dev)\n",
    "\n",
    "outputs = model(X_dev)\n",
    "outputs = outputs.detach().numpy()\n",
    "save_path = 'c:/Data/output/Y_pred_dev_learningrate=0.01_newdataset2.csv'\n",
    "np.savetxt(save_path, outputs, delimiter=',')\n",
    "\n",
    "test_percentage_error = calculate_percentage_error(X_test, Y_test)\n",
    "\n",
    "outputs = model(X_test)\n",
    "outputs = outputs.detach().numpy()\n",
    "save_path = 'c:/Data/output/Y_pred_dev_learningrate=0.01_newdataset2.csv'\n",
    "np.savetxt(save_path, outputs, delimiter=',')\n",
    "\n",
    "\n",
    "print('train_percentage_error:',train_percentage_error)\n",
    "print('dev_percentage_error:',dev_percentage_error)\n",
    "print('test_percentage_error:',test_percentage_error)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
